# EM聚类：期望最大化方法

每个簇可以用带参数的概率分布来描述，整个数据就是这些分布的混合，这样就可以使用K个概率分布的有限混合密度模型对数据进行聚类，其中每个分布代表一簇。其难点是如何估计概率的参数，使得分布最好地模拟数据。

期望最大化(Expectation Maximization)算法是一种流行的迭代求精算法，可以用来求参数的估计值，可以看做K-Means算法的一种扩展，基于簇的均值把对象指派到最相似的簇中。EM不是把每个对象指派到特定的簇，而是根据一个代表隶属概率的权重将每个对象指派到簇。换言之，簇之间没有严格的边界。因此，新的均值基于加权的度量来计算

EM首先是对混合模型的参数（整体成为参数向量）进行初始的估计，反复地根据参数的向量产生的混合密度对每个对象重新打分，重新打分之后的对象又用来更新参数的估计。算法描述如下：

<1>对参数向量做初步的估计：包括随机选择k个对象代表簇的均值或者中心（就像K-Means算法），以估计其他的参数。

<2>按照如下的两个步骤反复求精参数（或者簇）。
- ①期望步：计算每个对象xi指派到簇Ck的概率；换言之，这一步对每个簇计算对象xi的簇隶属概率。
- ②最大化步：利用前一步得到的概率重新估计（或者求精）模型参数。这一步是对给定的数据的分布似然“最大化”。

EM算法比较简单且容易实现。实践中，它收敛很快，但是可能达不到全局最优。对于某些特定的形式的优化函数，其收敛性可以得到保证。其计算复杂度线性于输入特征数、对象数和迭代次数。

贝叶斯聚类方法关注条件概率的密度的计算，广泛应用于统计学界。AutoClass是一种业界流行的贝叶斯聚类方法，是EM的算法的一个变种。给定对象的正确簇，最好的簇最大可能预测出对象的属性。